---
date: '2021-02-03'
title: 'Explainable AI'
type: 'Project Group'
year: '2021'
term: 'Summer'
kind: 'Master'
language: 'en'
---

While traditional machine learning models often constitute black boxes whose predictions are hardly comprehensible by humans, white box models make their predictions in a transparent way. Such white-box models are particularly promising to apply to knowledge graphs which represent knowledge in a human-readable form, e.g., as subject-predicate-object triples such as ("Paderborn", "has major", "Michael Dreier") or ("Paderborn", "has population", "151,633"). Popular examples of knowledge graphs include DBpedia, YAGO, and Wikipedia and they are heavily used by search engines such as Google, Bing, and Yahoo. In order to improve the quality of knowledge graphs and to infer new information, the goal of this project group is to develop explainable machine learning models for knowledge graphs.


## Related Work

Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Giannotti, F., & Pedreschi, D. (2018). A survey of methods for explaining black box models. ACM computing surveys (CSUR), 51(5), 1-42.

Lehmann, J., & Hitzler, P. (2010). Concept learning in description logics using refinement operators. Machine Learning, 78(1-2), 203.

## Contact

<Link to="/StefanHeindorf">Stefan Heindorf</Link>
